2024-03-14 10:24:30,352 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:24:30,990 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:24:30,995 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:24:31,068 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:25:14,456 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:25:14] "[33mGET / HTTP/1.1[0m" 404 -
2024-03-14 10:25:14,596 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:25:14] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-03-14 10:25:19,948 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:25:19] "GET /register HTTP/1.1" 200 -
2024-03-14 10:38:06,425 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\app\\user\\resource.py', reloading
2024-03-14 10:38:06,481 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:38:07,016 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:38:07,020 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:38:07,062 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:38:28,146 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:38:28,617 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:38:28,621 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:38:28,663 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:40:58,928 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:40:58] "[33mGET / HTTP/1.1[0m" 404 -
2024-03-14 10:41:15,488 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\app\\user\\__init__.py', reloading
2024-03-14 10:41:15,531 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:41:16,038 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:41:16,042 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:41:16,084 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:41:19,967 ERROR [resource.py]: 15 - get - error
2024-03-14 10:41:19,968 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:41:19,969 INFO [resource.py]: 17 - get - info
2024-03-14 10:41:21,583 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:41:21] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-03-14 10:42:18,028 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:42:18,513 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:42:18,517 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:42:18,559 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:42:19,966 ERROR [resource.py]: 15 - get - error
2024-03-14 10:42:19,967 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:42:19,968 INFO [resource.py]: 17 - get - info
2024-03-14 10:42:20,006 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:42:20] "GET /user/register HTTP/1.1" 200 -
2024-03-14 10:42:56,769 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\app\\user\\resource.py', reloading
2024-03-14 10:42:56,825 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:42:57,316 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:42:57,320 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:42:57,362 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:43:02,806 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:43:02] "POST /user/register HTTP/1.1" 200 -
2024-03-14 10:43:12,827 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:43:12] "[31m[1mPUT /user/register HTTP/1.1[0m" 405 -
2024-03-14 10:43:30,077 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:43:30,580 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:43:30,584 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:43:30,627 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:43:32,902 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:43:32] "[35m[1mPUT /user/register HTTP/1.1[0m" 500 -
2024-03-14 10:43:51,488 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:43:51] "PUT /user/register HTTP/1.1" 200 -
2024-03-14 10:43:58,410 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:43:58] "DELETE /user/register HTTP/1.1" 200 -
2024-03-14 10:44:27,836 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:44:27] "POST /user/register HTTP/1.1" 200 -
2024-03-14 10:44:32,162 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:44:32] "POST /user/register HTTP/1.1" 200 -
2024-03-14 10:49:50,375 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:49:51,139 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:49:51,144 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:49:51,208 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:49:52,782 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:49:52] "POST /user/register HTTP/1.1" 200 -
2024-03-14 10:51:17,312 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:51:17,810 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:51:17,814 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:51:17,862 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:51:20,064 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:51:20] "POST /user/register HTTP/1.1" 200 -
2024-03-14 10:52:27,839 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\middleware.py', reloading
2024-03-14 10:52:27,894 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:52:28,393 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:52:28,396 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:52:28,439 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:56:06,097 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 10:56:06,561 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 10:56:06,564 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 10:56:06,606 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 10:56:13,178 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:13] "PUT /user/register HTTP/1.1" 200 -
2024-03-14 10:56:17,690 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:17] "[31m[1mPATCH /user/register HTTP/1.1[0m" 405 -
2024-03-14 10:56:22,315 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:22] "OPTIONS /user/register HTTP/1.1" 200 -
2024-03-14 10:56:27,402 ERROR [resource.py]: 15 - get - error
2024-03-14 10:56:27,406 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:56:27,410 INFO [resource.py]: 17 - get - info
2024-03-14 10:56:27,432 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:27] "HEAD /user/register HTTP/1.1" 200 -
2024-03-14 10:56:30,070 ERROR [resource.py]: 15 - get - error
2024-03-14 10:56:30,073 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:56:30,075 INFO [resource.py]: 17 - get - info
2024-03-14 10:56:30,085 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:30] "HEAD /user/register HTTP/1.1" 200 -
2024-03-14 10:56:31,105 ERROR [resource.py]: 15 - get - error
2024-03-14 10:56:31,110 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:56:31,113 INFO [resource.py]: 17 - get - info
2024-03-14 10:56:31,123 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:56:31] "HEAD /user/register HTTP/1.1" 200 -
2024-03-14 10:57:55,028 ERROR [resource.py]: 15 - get - error
2024-03-14 10:57:55,032 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:57:55,035 INFO [resource.py]: 17 - get - info
2024-03-14 10:57:55,046 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:57:55] "GET /user/register HTTP/1.1" 200 -
2024-03-14 10:57:55,999 ERROR [resource.py]: 15 - get - error
2024-03-14 10:57:56,004 DEBUG [resource.py]: 16 - get - debug
2024-03-14 10:57:56,007 INFO [resource.py]: 17 - get - info
2024-03-14 10:57:56,022 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 10:57:56] "GET /user/register HTTP/1.1" 200 -
2024-03-14 11:11:38,662 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\util\\log_util.py', reloading
2024-03-14 11:11:38,762 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 11:11:39,364 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 11:11:39,368 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 11:11:39,410 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 11:12:18,974 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\app\\user\\resource.py', reloading
2024-03-14 11:12:19,038 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 11:12:37,360 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 11:12:37,834 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 11:12:37,837 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 11:12:37,877 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 13:19:07,415 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 13:19:07,890 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 13:19:07,893 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 13:19:07,935 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 13:19:22,058 ERROR [resource.py]: 15 - get - error
2024-03-14 13:19:22,058 DEBUG [resource.py]: 16 - get - debug
2024-03-14 13:19:22,060 INFO [resource.py]: 17 - get - info
2024-03-14 13:19:22,108 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 13:19:22] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-03-14 13:21:14,460 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 13:21:14,936 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 13:21:14,940 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 13:21:14,982 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 13:21:17,454 ERROR [resource.py]: 15 - get - error
2024-03-14 13:21:17,455 DEBUG [resource.py]: 16 - get - debug
2024-03-14 13:21:17,456 INFO [resource.py]: 17 - get - info
2024-03-14 13:21:17,498 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 13:21:17] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-03-14 13:22:10,172 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 13:22:10,650 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 13:22:10,654 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 13:22:10,700 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 13:22:12,548 ERROR [resource.py]: 15 - get - error
2024-03-14 13:22:12,548 DEBUG [resource.py]: 16 - get - debug
2024-03-14 13:22:12,549 INFO [resource.py]: 17 - get - info
2024-03-14 13:22:12,600 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 13:22:12] "GET /user/register HTTP/1.1" 200 -
2024-03-14 13:22:15,301 ERROR [resource.py]: 15 - get - error
2024-03-14 13:22:15,302 DEBUG [resource.py]: 16 - get - debug
2024-03-14 13:22:15,303 INFO [resource.py]: 17 - get - info
2024-03-14 13:22:15,307 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 13:22:15] "GET /user/register HTTP/1.1" 200 -
2024-03-14 14:08:24,079 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 14:08:24,621 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 14:08:24,626 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 14:08:24,680 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 14:10:01,746 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 14:10:02,504 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 14:10:02,507 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 14:10:02,570 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 14:10:07,885 ERROR [resource.py]: 16 - get - error
2024-03-14 14:10:07,885 DEBUG [resource.py]: 17 - get - debug
2024-03-14 14:10:07,887 INFO [resource.py]: 18 - get - info
2024-03-14 14:10:07,888 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:10:07,889 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:10:07,897 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:10:07,897 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:10:07,904 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:10:07,905 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:11:23,980 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 14:11:24,776 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 14:11:24,780 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 14:11:24,839 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 14:11:28,886 ERROR [resource.py]: 16 - get - error
2024-03-14 14:11:28,887 DEBUG [resource.py]: 17 - get - debug
2024-03-14 14:11:28,887 INFO [resource.py]: 18 - get - info
2024-03-14 14:11:28,889 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:11:28,890 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:11:28,897 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:11:28,899 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:11:28,905 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:11:28,905 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:11:28,916 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '你是一个聊天机器人'}, {'role': 'user', 'content': '测试api接口'}], 'model': 'gpt-3.5-turbo'}}
2024-03-14 14:11:28,970 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-14 14:11:28,972 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2F92E14B0>
2024-03-14 14:11:28,972 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:11:28,972 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:11:28,974 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-14 14:11:28,974 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:11:28,975 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:11:28,975 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-14 14:11:28,976 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A2F91ABF40> server_hostname='api.openai.com' timeout=5.0
2024-03-14 14:11:29,512 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2F92E14E0>
2024-03-14 14:11:29,513 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-14 14:11:29,516 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:11:29,517 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-14 14:11:29,518 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:11:29,518 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-14 14:11:32,150 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Mar 2024 06:11:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'1890'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39971'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_b13b49cd1dce90744c748acc40dad48b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gHJqVVNFDIO2TqFE2ucUd6CEpwLPw2EZqE2vW03xT34-1710396691-1.0.1.1-Xc6urWnBtv_ekIS4exCWS4ckbUqUVM58BkmVR4M63rDt5Z0zT0MXHBkwsXJfgoM65SPn.x4e5BjzWQyRJRaWIA; path=/; expires=Thu, 14-Mar-24 06:41:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bo.j4FoGEektciFRPK3DKUDxTLjoZCI7sXg6TwXNn5k-1710396691665-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86421b4cbcb8cfd5-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-14 14:11:32,154 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-14 14:11:32,156 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-14 14:11:32,178 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-14 14:11:32,180 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-14 14:11:32,181 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-14 14:11:32,183 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-14 14:11:32,187 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 14:11:32] "GET /user/register HTTP/1.1" 200 -
2024-03-14 14:25:24,925 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:24,927 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:24,935 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:24,936 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:24,943 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:24,944 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:24,963 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 14:25:25,785 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:25,787 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:25,793 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:25,794 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:25,801 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:25:25,802 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:25:25,816 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 14:25:25,821 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 14:25:25,889 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 14:25:33,694 ERROR [resource.py]: 17 - get - error
2024-03-14 14:25:33,695 DEBUG [resource.py]: 18 - get - debug
2024-03-14 14:25:33,696 INFO [resource.py]: 19 - get - info
2024-03-14 14:25:33,699 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '你是一个聊天机器人'}, {'role': 'user', 'content': '测试api接口'}], 'model': 'gpt-3.5-turbo'}}
2024-03-14 14:25:33,756 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-14 14:25:33,757 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001399FD19240>
2024-03-14 14:25:33,758 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:25:33,758 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:25:33,759 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-14 14:25:33,760 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:25:33,760 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:25:33,761 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-14 14:25:33,762 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001399FBF25C0> server_hostname='api.openai.com' timeout=5.0
2024-03-14 14:25:34,453 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001399FD19270>
2024-03-14 14:25:34,454 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-14 14:25:34,455 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:25:34,456 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-14 14:25:34,457 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:25:34,457 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-14 14:25:36,786 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Mar 2024 06:25:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'1780'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39971'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_f136a8984ab669e5410aa6943d5b158b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OXjRYGKd0kdHpc3i9B0RX5Wx2pFZIsK82xGB.QjlDws-1710397536-1.0.1.1-qGv9w9fQpIvDGBBftOuFDW1iw4s_j_sBQnN7aoDyqPyGFxkMMu1DNp_18RZZP_7LoA4R4FNXarpdwKBhntEydg; path=/; expires=Thu, 14-Mar-24 06:55:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=aXf0eiFHoR_O0na8n8IsPfOQUCWd34UQ2WOsoyhswO8-1710397536278-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86422fed985f6447-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-14 14:25:36,789 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-14 14:25:36,790 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-14 14:25:36,818 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-14 14:25:36,819 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-14 14:25:36,820 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-14 14:25:36,821 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-14 14:25:36,823 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 14:25:36] "GET /user/register HTTP/1.1" 200 -
2024-03-14 14:34:24,936 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:24,937 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:24,945 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:24,946 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:24,953 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:24,953 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:24,973 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-14 14:34:25,786 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:25,788 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:25,795 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:25,796 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:25,802 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-14 14:34:25,803 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-14 14:34:25,817 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-14 14:34:25,821 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-14 14:34:25,887 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-14 14:34:28,309 ERROR [resource.py]: 17 - get - error
2024-03-14 14:34:28,309 DEBUG [resource.py]: 18 - get - debug
2024-03-14 14:34:28,310 INFO [resource.py]: 19 - get - info
2024-03-14 14:34:28,314 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '你是一个聊天机器人'}, {'role': 'user', 'content': 'freeipa client之间怎么做到免密登录的'}], 'model': 'gpt-3.5-turbo'}}
2024-03-14 14:34:28,369 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-14 14:34:28,370 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000275BF3C9240>
2024-03-14 14:34:28,371 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:34:28,371 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:34:28,372 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-14 14:34:28,372 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:34:28,373 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-14 14:34:28,374 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-14 14:34:28,374 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000275BF2A25C0> server_hostname='api.openai.com' timeout=5.0
2024-03-14 14:34:29,141 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000275BF3C9270>
2024-03-14 14:34:29,142 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-14 14:34:29,143 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-14 14:34:29,143 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-14 14:34:29,143 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-14 14:34:29,144 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-14 14:34:35,206 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Mar 2024 06:34:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5156'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39963'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'55ms'), (b'x-request-id', b'req_c21b5a2f652c0ee075c10f44b6078255'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Kscv9KEdkhapnlHug9J3ZKJYrKRiaAgsO8smoINAf08-1710398074-1.0.1.1-qyOkdY39vR4GatGFHH1Mj5ui195ksTuzrSA9UvNEMa.YMILifAHn5BYCFQvTeSYprah9SizzXfRfKM_58DkJJw; path=/; expires=Thu, 14-Mar-24 07:04:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YqwY1zkcsbzI3aKqix5aWcVhoikp4ZMLQdppj2v9wQs-1710398074705-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86423cfdccad17e4-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-14 14:34:35,213 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-14 14:34:35,216 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-14 14:34:35,231 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-14 14:34:35,234 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-14 14:34:35,236 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-14 14:34:35,239 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-14 14:34:35,246 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [14/Mar/2024 14:34:35] "GET /user/register HTTP/1.1" 200 -
2024-03-15 16:53:45,425 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:45,427 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:45,438 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:45,440 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:45,449 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:45,450 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:45,481 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-15 16:53:46,556 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:46,558 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:46,568 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:46,570 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:46,579 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-15 16:53:46,580 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-15 16:53:46,600 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-15 16:53:46,605 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-03-15 16:53:46,701 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-15 16:53:48,385 ERROR [resource.py]: 17 - get - error
2024-03-15 16:53:48,386 DEBUG [resource.py]: 18 - get - debug
2024-03-15 16:53:48,387 INFO [resource.py]: 19 - get - info
2024-03-15 16:53:48,393 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '你是一个聊天机器人'}, {'role': 'user', 'content': 'freeipa client之间怎么做到免密登录的'}], 'model': 'gpt-3.5-turbo'}}
2024-03-15 16:53:48,454 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-15 16:53:48,469 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BB0445D240>
2024-03-15 16:53:48,470 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-15 16:53:48,471 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-15 16:53:48,472 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-15 16:53:48,472 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-15 16:53:48,473 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-15 16:53:48,474 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-15 16:53:48,475 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BB043325C0> server_hostname='api.openai.com' timeout=5.0
2024-03-15 16:53:49,324 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BB0445D270>
2024-03-15 16:53:49,325 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-15 16:53:49,326 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-15 16:53:49,327 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-15 16:53:49,327 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-15 16:53:49,328 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-15 16:53:57,738 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 15 Mar 2024 08:53:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'7796'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39963'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'55ms'), (b'x-request-id', b'req_0e485fcc616ca5f5d30129d9656472cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ox5mHY42rvS0du7PcCh9lVnUKzw5avpuc0V80YSid0Q-1710492837-1.0.1.1-YNHRjZrhPuqjuW0fYvwu1O434oNXoMOQg.nRCd4ocrZW1EOweDUjLCiDDtRI3vLktsemftnkgfHEmJNObwwbMg; path=/; expires=Fri, 15-Mar-24 09:23:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1FWaiApaoRBeeNKxZJzDVPx8YTCEIRlIz_17I0_ffj4-1710492837812-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'864b467a0deb9e6b-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-15 16:53:57,740 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-15 16:53:57,741 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-15 16:53:57,759 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-15 16:53:57,761 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-15 16:53:57,762 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-15 16:53:57,763 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-15 16:53:57,767 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [15/Mar/2024 16:53:57] "GET /user/register HTTP/1.1" 200 -
2024-03-20 09:49:36,168 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:36,170 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:36,177 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:36,177 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:36,184 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:36,186 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:36,208 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-20 09:49:37,002 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:37,003 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:37,011 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:37,011 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:37,017 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-20 09:49:37,018 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-20 09:49:37,032 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-20 09:49:37,036 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-20 09:49:37,099 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-20 09:49:39,283 ERROR [resource.py]: 17 - get - error
2024-03-20 09:49:39,284 DEBUG [resource.py]: 18 - get - debug
2024-03-20 09:49:39,285 INFO [resource.py]: 19 - get - info
2024-03-20 09:49:39,289 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa client之间怎么做到免密登录的'}], 'model': 'gpt-3.5-turbo'}}
2024-03-20 09:49:39,345 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-20 09:49:39,369 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BD04154B80>
2024-03-20 09:49:39,370 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-20 09:49:39,371 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-20 09:49:39,372 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-20 09:49:39,373 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-20 09:49:39,373 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-20 09:49:39,375 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-20 09:49:39,376 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002BD040325C0> server_hostname='api.openai.com' timeout=5.0
2024-03-20 09:49:39,793 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BD04154BB0>
2024-03-20 09:49:39,793 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-20 09:49:39,794 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-20 09:49:39,795 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-20 09:49:39,796 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-20 09:49:39,797 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-20 09:49:45,785 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 20 Mar 2024 01:49:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'199'), (b'x-ratelimit-remaining-tokens', b'39971'), (b'x-ratelimit-reset-requests', b'7m12s'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_3c4472a2e2082e7c30f587d66deb1468'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=93PBoi9WFlD8aYyirzs4Kmwc24dhRy7D06cnovAjjAU-1710899383-1.0.1.1-snAnHZnnrWwkyasZ6WTL8WBQ2VqvEJcVieQZNWIJ7Vgpb3seE64heTO6Mkz84R5s4Q0jwSStc0EGZ9y52mKbCQ; path=/; expires=Wed, 20-Mar-24 02:19:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xyhI5S0c.0hqPtKTUTkUXxm8Cmued2YBBH7jUpneBU8-1710899383737-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86720bf8eed7ced9-SJC'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-20 09:49:45,792 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-20 09:49:45,795 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-20 09:49:45,800 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-20 09:49:45,804 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-20 09:49:45,809 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-20 09:49:45,812 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-20 09:49:45,819 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [20/Mar/2024 09:49:45] "GET /user/register HTTP/1.1" 200 -
2024-03-22 15:14:04,690 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:04,693 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:04,702 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:04,703 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:04,712 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:04,713 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:23,035 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:23,041 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:23,051 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:23,052 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:23,061 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:23,063 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:45,750 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:45,752 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:45,761 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:45,763 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:45,772 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:45,773 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:45,805 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:14:46,790 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:46,792 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:46,801 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:46,803 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:46,811 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:14:46,812 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:14:46,836 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:14:46,841 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:14:46,924 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:16:01,174 ERROR [resource.py]: 15 - get - error
2024-03-22 15:16:01,178 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:16:01,184 INFO [resource.py]: 17 - get - info
2024-03-22 15:16:01,201 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa client之间怎么做到免密登录的'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:16:01,294 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:16:01,300 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000295FAA5C370>
2024-03-22 15:16:01,306 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:16:01,312 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:16:01,314 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:16:01,317 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:16:01,320 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:16:01,323 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:16:01,329 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000295FA91E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:16:02,229 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000295FA9F9150>
2024-03-22 15:16:02,237 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:16:02,242 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:16:02,244 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:16:02,247 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:16:02,250 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:16:15,336 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:16:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'12482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'197'), (b'x-ratelimit-remaining-tokens', b'39971'), (b'x-ratelimit-reset-requests', b'20m1.719s'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_508b8226b72b1fc4d7a225796f0b954a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qdzMN9rmf4de6qOoQ0vDpxxdaQEBIUiYcQXBYidjYKg-1711091773-1.0.1.1-FTPW5qzNpJlv5W48wK7TzMRCewizyZSm0lg0GwYiNM7IvQsJsR4rqI3dfLlKU756cmAh0dsCDhrHfcCkhhsPtw; path=/; expires=Fri, 22-Mar-24 07:46:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=V1.eiGVUKnxYA5a6wp_3wJrnAFSjjaHnhkCx8sP4Ae0-1711091773047-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868464ce2b93f255-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:16:15,342 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:16:15,345 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:16:15,348 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:16:15,350 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:16:15,352 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:16:15,356 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:16:15,427 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:16:15] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-03-22 15:17:28,267 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\apps\\user\\resource.py', reloading
2024-03-22 15:17:28,360 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:17:29,433 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:29,435 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:29,445 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:29,446 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:29,455 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:29,456 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:29,482 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:17:29,487 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:17:29,573 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:17:34,807 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:34,810 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:34,821 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:34,822 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:34,832 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:34,833 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:34,863 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:17:35,809 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:35,812 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:35,820 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:35,821 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:35,830 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:17:35,831 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:17:35,855 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:17:35,859 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:17:35,940 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:18:06,539 ERROR [resource.py]: 15 - get - error
2024-03-22 15:18:06,541 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:18:06,542 INFO [resource.py]: 17 - get - info
2024-03-22 15:18:06,552 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:18:06] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-03-22 15:18:16,506 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:16,508 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:16,517 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:16,518 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:16,527 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:16,529 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:16,557 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:18:17,590 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:17,592 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:17,602 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:17,603 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:17,612 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:18:17,613 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:18:17,637 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:18:17,641 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:18:17,728 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:18:23,482 ERROR [resource.py]: 15 - get - error
2024-03-22 15:18:23,483 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:18:23,484 INFO [resource.py]: 17 - get - info
2024-03-22 15:18:23,496 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa client之间怎么做到免密登录的'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:18:23,552 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:18:23,554 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019205C6C1F0>
2024-03-22 15:18:23,555 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:18:23,556 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:18:23,557 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:18:23,558 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:18:23,559 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:18:23,559 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:18:23,560 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000019205B2E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:18:24,667 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019205C6C220>
2024-03-22 15:18:24,668 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:18:24,669 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:18:24,670 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:18:24,671 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:18:24,672 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:18:34,260 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:18:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'9018'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'196'), (b'x-ratelimit-remaining-tokens', b'39971'), (b'x-ratelimit-reset-requests', b'24m51.277s'), (b'x-ratelimit-reset-tokens', b'43ms'), (b'x-request-id', b'req_2a27cd31d9e9259d4456a11757a0894a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=N_fsYBN3rlqvY50QWYANzkVIlWFLYU1ida87UOF5iKw-1711091912-1.0.1.1-OK7qps2cNlylfRF_DiiXaEQjvdSOiyJIfFmYAwIM5MYEjdWFmTEhdA_JryGSOdhj17JhcMPPTV_WyjFrABvtxQ; path=/; expires=Fri, 22-Mar-24 07:48:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iWPUTsbrEwWuAWMj7gDNUu5ZeNRvUvp2O6Ig_MjV9Vw-1711091912012-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868468485944f1cc-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:18:34,267 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:18:34,272 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:18:34,277 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:18:34,284 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:18:34,287 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:18:34,290 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:18:34,311 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:18:34] "GET /user/register HTTP/1.1" 200 -
2024-03-22 15:27:52,436 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\apps\\user\\resource.py', reloading
2024-03-22 15:27:52,515 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:27:53,526 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:27:53,528 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:27:53,539 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:27:53,540 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:27:53,552 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:27:53,553 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:27:53,583 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:27:53,589 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:27:53,692 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:28:45,346 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:45,349 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:45,360 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:45,361 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:45,372 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:45,373 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:45,408 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:28:46,567 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:46,570 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:46,582 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:46,583 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:46,595 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:28:46,597 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:28:46,626 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:28:46,632 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:28:46,777 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:29:25,327 ERROR [resource.py]: 15 - get - error
2024-03-22 15:29:25,333 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:29:25,341 INFO [resource.py]: 17 - get - info
2024-03-22 15:29:25,367 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:29:25,443 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:29:25,466 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C529C400>
2024-03-22 15:29:25,473 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:29:25,478 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:29:25,480 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:29:25,483 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:29:25,485 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:29:25,493 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:29:25,502 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:29:26,205 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5239150>
2024-03-22 15:29:26,209 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:29:26,213 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:29:26,215 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:29:26,218 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:29:26,221 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:29:31,968 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:29:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5174'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'197'), (b'x-ratelimit-remaining-tokens', b'39979'), (b'x-ratelimit-reset-requests', b'21m1.743s'), (b'x-ratelimit-reset-tokens', b'31ms'), (b'x-request-id', b'req_6d806beb2e20c6e8d153b1770c6459ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6U_.DEZQNXBvQrduC_lkVtMyLMSxsuFSI2DU9hdShGU-1711092569-1.0.1.1-bNgo3sokJObGdNv2iXUIcoptLqzldEVJDfA_UlNNovYcv49Ud3ZlEMAuRAeyDNXxrWQwSM5JC_EMi2Dz0PfMUQ; path=/; expires=Fri, 22-Mar-24 07:59:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=vossl1DzgKVwTqyyZ.mA2xP18SApr8ID23HrJuecUG4-1711092569720-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8684786ef8b2f228-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:29:31,977 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:29:31,981 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:29:31,984 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:29:31,986 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:29:31,988 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:29:31,991 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:29:32,020 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:29:32] "GET /user/register?message=freeipa安装 HTTP/1.1" 200 -
2024-03-22 15:29:43,500 ERROR [resource.py]: 15 - get - error
2024-03-22 15:29:43,506 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:29:43,513 INFO [resource.py]: 17 - get - info
2024-03-22 15:29:43,529 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:29:43,534 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:29:43,559 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C52D4190>
2024-03-22 15:29:43,562 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:29:43,565 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:29:43,567 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:29:43,569 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:29:43,571 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:29:43,574 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:29:43,578 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:29:44,324 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C52D41C0>
2024-03-22 15:29:44,329 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:29:44,332 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:29:44,334 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:29:44,337 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:29:44,338 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:29:54,137 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:29:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'9128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'196'), (b'x-ratelimit-remaining-tokens', b'39775'), (b'x-ratelimit-reset-requests', b'27m55.62s'), (b'x-ratelimit-reset-tokens', b'337ms'), (b'x-request-id', b'req_fc46e799760f6260885db3767a517739'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=S3AsmOErXCZo2yuOfb9XGG2UjCWMAq0HVxoRamh3sL4-1711092591-1.0.1.1-pzygalrboC2xYBGY2987CfI9O02mDNG6x5FQI0HcoHma272cBS25V.lkJuT4oy1Egh0lwLafo1k2tA5P8juhxQ; path=/; expires=Fri, 22-Mar-24 07:59:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oG31QcW23lIGsVezcjQSDWEGSYp54COwfgyXQyqR5NQ-1711092591881-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868478e03d02f23c-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:29:54,143 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:29:54,146 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:29:54,148 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:29:54,151 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:29:54,153 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:29:54,156 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:29:54,175 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:29:54] "GET /user/register?message=freeipa源码安装 HTTP/1.1" 200 -
2024-03-22 15:30:57,686 ERROR [resource.py]: 15 - get - error
2024-03-22 15:30:57,689 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:30:57,692 INFO [resource.py]: 17 - get - info
2024-03-22 15:30:57,728 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:30:57,733 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:30:57,737 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C52E8250>
2024-03-22 15:30:57,740 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:30:57,743 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:30:57,745 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:30:57,747 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:30:57,749 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:30:57,752 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:30:57,755 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:30:58,263 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))
2024-03-22 15:30:58,271 DEBUG [_base_client.py]: 939 - _request - Encountered Exception
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)
2024-03-22 15:30:58,308 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 15:30:58,313 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.788869 seconds
2024-03-22 15:30:59,111 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:30:59,116 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:30:59,141 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C52E9330>
2024-03-22 15:30:59,144 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:30:59,147 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:30:59,148 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:30:59,150 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:30:59,152 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:30:59,155 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:30:59,162 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:30:59,262 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))
2024-03-22 15:30:59,273 DEBUG [_base_client.py]: 939 - _request - Encountered Exception
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)
2024-03-22 15:30:59,287 DEBUG [_base_client.py]: 1004 - _retry_request - 0 retries left
2024-03-22 15:30:59,290 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 1.772260 seconds
2024-03-22 15:31:01,080 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:31:01,093 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:31:01,111 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C52E9960>
2024-03-22 15:31:01,120 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:01,127 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:31:01,135 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:31:01,140 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:31:01,144 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:01,150 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:31:01,156 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:31:06,167 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:980: The handshake operation timed out'))
2024-03-22 15:31:06,170 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:980: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:980: The handshake operation timed out
2024-03-22 15:31:06,176 DEBUG [_base_client.py]: 936 - _request - Raising timeout error
2024-03-22 15:31:06,484 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:06] "[35m[1mGET /user/register?message=freeipa源码安装 HTTP/1.1[0m" 500 -
2024-03-22 15:31:07,480 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:07] "GET /user/register?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2024-03-22 15:31:07,483 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:07] "GET /user/register?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2024-03-22 15:31:07,574 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:07] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-03-22 15:31:07,869 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:07] "GET /user/register?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1" 200 -
2024-03-22 15:31:07,940 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:07] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-03-22 15:31:11,526 ERROR [resource.py]: 15 - get - error
2024-03-22 15:31:11,529 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:31:11,532 INFO [resource.py]: 17 - get - info
2024-03-22 15:31:11,579 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:31:11,593 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:31:11,623 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AAB670>
2024-03-22 15:31:11,634 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:11,643 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:31:11,646 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:31:11,648 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:31:11,651 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:11,653 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:31:11,655 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:31:16,662 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectTimeout(TimeoutError('_ssl.c:980: The handshake operation timed out'))
2024-03-22 15:31:16,665 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: _ssl.c:980: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: _ssl.c:980: The handshake operation timed out
2024-03-22 15:31:16,672 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 15:31:16,674 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.761276 seconds
2024-03-22 15:31:17,449 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:31:17,454 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:31:17,479 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AAC760>
2024-03-22 15:31:17,482 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:17,486 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:31:17,488 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:31:17,490 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:31:17,493 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:31:17,498 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:31:17,502 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:31:18,169 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AAC790>
2024-03-22 15:31:18,173 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:31:18,177 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:31:18,179 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:31:18,183 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:31:18,185 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:31:31,272 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:31:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'11994'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'195'), (b'x-ratelimit-remaining-tokens', b'39371'), (b'x-ratelimit-reset-requests', b'33m33.76s'), (b'x-ratelimit-reset-tokens', b'943ms'), (b'x-request-id', b'req_1c2d74546f01496fe2c813056234774a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=i5Za8zyfGVzzO7eYLqw7C4oK4GRJT3nIscTClI_HUlQ-1711092689-1.0.1.1-j1Ou.rHgn4yNpITWKuMaajNRlTXEl09_n9snQzAR.t2zmDC7XdU2eTs_VX6tXrfp8nbG3yEsEBjDH0we6LZkag; path=/; expires=Fri, 22-Mar-24 08:01:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tuneNfeMLog2HBZu8.38DiVE.v9nF6Uk5o61BsxZN6I-1711092689038-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86847b2abf5cf212-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:31:31,276 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:31:31,280 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:31:31,285 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:31:31,289 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:31:31,292 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:31:31,296 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:31:31,318 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:31] "GET /user/register?message=freeipa源码安装 HTTP/1.1" 200 -
2024-03-22 15:31:31,400 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:31:31] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-03-22 15:32:53,944 ERROR [resource.py]: 15 - get - error
2024-03-22 15:32:53,945 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:32:53,946 INFO [resource.py]: 17 - get - info
2024-03-22 15:32:53,958 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装依赖项：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。可以根据您的系统环境运行以下命令：\n```\nsudo yum install -y epel-release\nsudo yum install -y @development-tools\nsudo yum install -y python3-devel python3-cffi python3-gssapi python3-libipa_hbac python3-netifaces python3-pyOpenSSL\n```\n\n3. 配置和安装FreeIPA：\n进入下载的FreeIPA源代码目录，运行以下命令进行配置和安装：\n```\ncd freeipa\nmake\nsudo make install\n```\n\n4. 初始化FreeIPA服务器：\n运行以下命令以初始化FreeIPA服务器：\n```\nsudo ipa-server-install\n```\n\n5. 配置FreeIPA服务器：\n按照安装向导的指示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n6. 启动FreeIPA服务：\n启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa\nsudo systemctl enable ipa\n```\n\n7. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n8. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:32:53,963 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:32:53,981 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AAFAC0>
2024-03-22 15:32:53,982 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:32:53,983 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:32:53,984 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:32:53,984 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:32:53,985 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:32:53,986 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:32:53,987 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:32:55,154 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AAFAF0>
2024-03-22 15:32:55,155 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:32:55,156 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:32:55,157 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:32:55,158 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:32:55,159 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:32:56,445 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:32:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'617'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'194'), (b'x-ratelimit-remaining-tokens', b'38982'), (b'x-ratelimit-reset-requests', b'39m8.798s'), (b'x-ratelimit-reset-tokens', b'1.527s'), (b'x-request-id', b'req_d8f5187097294a27b131e773fa9a9b72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AFt5tcsa29.0O9I49xS.Fa7IX4ltC5Ilk_9hltruY7A-1711092774-1.0.1.1-0HS64wLMKa.Z.q.GaX0F0Jm0BNZgt_J1fO1K30M7ssFLrgmgJ6cYXmQuExkPdIZ19F3ChM.vRraIS51YSlTm9A; path=/; expires=Fri, 22-Mar-24 08:02:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RibeCycWGnxyA.Rdlii0g1zvo3TA_Dhvrnfjz4M7Quw-1711092774161-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86847d88ff05f1b8-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:32:56,447 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:32:56,447 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:32:56,448 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:32:56,449 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:32:56,449 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:32:56,450 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:32:56,458 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:32:56] "GET /user/register?message=freeipa HTTP/1.1" 200 -
2024-03-22 15:33:08,200 ERROR [resource.py]: 15 - get - error
2024-03-22 15:33:08,205 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:33:08,211 INFO [resource.py]: 17 - get - info
2024-03-22 15:33:08,278 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装依赖项：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。可以根据您的系统环境运行以下命令：\n```\nsudo yum install -y epel-release\nsudo yum install -y @development-tools\nsudo yum install -y python3-devel python3-cffi python3-gssapi python3-libipa_hbac python3-netifaces python3-pyOpenSSL\n```\n\n3. 配置和安装FreeIPA：\n进入下载的FreeIPA源代码目录，运行以下命令进行配置和安装：\n```\ncd freeipa\nmake\nsudo make install\n```\n\n4. 初始化FreeIPA服务器：\n运行以下命令以初始化FreeIPA服务器：\n```\nsudo ipa-server-install\n```\n\n5. 配置FreeIPA服务器：\n按照安装向导的指示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n6. 启动FreeIPA服务：\n启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa\nsudo systemctl enable ipa\n```\n\n7. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n8. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': '请问您需要关于FreeIPA的信息还是有其他问题需要帮助的呢？'}, {'role': 'user', 'content': '前者'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:33:08,287 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:33:08,290 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AC43D0>
2024-03-22 15:33:08,293 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:33:08,299 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:33:08,304 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:33:08,307 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:33:08,309 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:33:08,312 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:33:08,314 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:33:09,067 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5239F30>
2024-03-22 15:33:09,073 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:33:09,076 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:33:09,078 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:33:09,081 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:33:09,084 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:33:19,533 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:33:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'9355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'193'), (b'x-ratelimit-remaining-tokens', b'38959'), (b'x-ratelimit-reset-requests', b'46m6.864s'), (b'x-ratelimit-reset-tokens', b'1.561s'), (b'x-request-id', b'req_6ce52d3528df269be2c6c9362804f3ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HrmlMzLWUBFsguLl5iGC8c3daSpxDgd__b9VE2os7Xs-1711092797-1.0.1.1-l5oYr479Y9hUg7aJhtBhuCp20E6Xc2XhOfCQNqzeknibnKprYryDVaYPf4xAT1E0s4qrCrcIuOH3q8MpHOPn9Q; path=/; expires=Fri, 22-Mar-24 08:03:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XquWi11Em2lAfBWm8IsLvIHXIGKIQolirMaF9m53XMw-1711092797284-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86847ddffa15f1c8-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:33:19,541 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:33:19,545 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:33:19,549 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:33:19,552 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:33:19,555 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:33:19,557 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:33:19,575 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:33:19] "GET /user/register?message=前者 HTTP/1.1" 200 -
2024-03-22 15:33:52,903 ERROR [resource.py]: 15 - get - error
2024-03-22 15:33:52,907 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:33:52,911 INFO [resource.py]: 17 - get - info
2024-03-22 15:33:53,010 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装依赖项：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。可以根据您的系统环境运行以下命令：\n```\nsudo yum install -y epel-release\nsudo yum install -y @development-tools\nsudo yum install -y python3-devel python3-cffi python3-gssapi python3-libipa_hbac python3-netifaces python3-pyOpenSSL\n```\n\n3. 配置和安装FreeIPA：\n进入下载的FreeIPA源代码目录，运行以下命令进行配置和安装：\n```\ncd freeipa\nmake\nsudo make install\n```\n\n4. 初始化FreeIPA服务器：\n运行以下命令以初始化FreeIPA服务器：\n```\nsudo ipa-server-install\n```\n\n5. 配置FreeIPA服务器：\n按照安装向导的指示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n6. 启动FreeIPA服务：\n启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa\nsudo systemctl enable ipa\n```\n\n7. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n8. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': '请问您需要关于FreeIPA的信息还是有其他问题需要帮助的呢？'}, {'role': 'user', 'content': '前者'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，提供集中管理用户、组、主机、权限和安全策略的功能。它结合了多个开源项目，如LDAP、Kerberos、DNS等，为组织提供了一个完整的身份和访问管理平台。以下是FreeIPA的一些主要特点和功能：\n\n1. 用户管理：可以在FreeIPA中集中管理用户的帐户信息、权限和访问控制。管理员可以创建、编辑和删除用户帐户，并设置访问策略。\n\n2. 组管理：可以创建和管理组，将用户分组以方便管理和分配权限。\n\n3. 主机管理：可以将主机（包括服务器和客户端）注册到FreeIPA服务中，从而实现对主机的集中管理。\n\n4. 安全认证：FreeIPA集成了Kerberos身份认证系统，提供安全的身份验证机制，确保用户安全地访问系统资源。\n\n5. 证书管理：支持证书颁发机构（CA）和数字证书管理，为系统和应用程序提供安全的通信和身份验证支持。\n\n6. 多因素认证：支持多种认证方法，包括密码、OTP（一次性密码）、智能卡等，提高系统安全性。\n\n7. 访问审计：可以监控和审计用户访问系统资源的行为，帮助管理员了解系统使用情况，发现潜在的安全问题。\n\n总的来说，FreeIPA是一个功能强大、灵活且安全的身份管理解决方案，适用于中小型组织和企业，提供了一站式的身份和访问管理平台。'}, {'role': 'user', 'content': 'Kerberos身份认证系统'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:33:53,023 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:33:53,030 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5ACD9C0>
2024-03-22 15:33:53,031 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:33:53,033 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:33:53,036 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:33:53,042 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:33:53,049 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:33:53,052 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:33:53,054 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:33:53,765 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5ACD9F0>
2024-03-22 15:33:53,769 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:33:53,776 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:33:53,780 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:33:53,783 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:33:53,787 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:34:02,909 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:34:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'8461'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'192'), (b'x-ratelimit-remaining-tokens', b'38587'), (b'x-ratelimit-reset-requests', b'52m34.133s'), (b'x-ratelimit-reset-tokens', b'2.119s'), (b'x-request-id', b'req_e0aa5e78e2260d3886b57a73f63397df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86847ef73f13f1b8-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:34:02,919 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:34:02,923 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:34:02,926 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:34:02,928 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:34:02,931 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:34:02,933 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:34:02,959 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:34:02] "GET /user/register?message=Kerberos身份认证系统 HTTP/1.1" 200 -
2024-03-22 15:34:28,306 ERROR [resource.py]: 15 - get - error
2024-03-22 15:34:28,312 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:34:28,318 INFO [resource.py]: 17 - get - info
2024-03-22 15:34:28,429 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份和访问管理解决方案，它基于LDAP和Kerberos。下面是在CentOS系统上安装FreeIPA的步骤：\n\n1. 在CentOS系统上安装FreeIPA软件包：\n```\nsudo yum install ipa-server\n```\n\n2. 运行FreeIPA服务器安装向导：\n```\nsudo ipa-server-install\n```\n\n3. 按照向导的提示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n4. 启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa.service\nsudo systemctl enable ipa.service\n```\n\n5. 使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n6. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望这些步骤能够帮助您成功安装和配置FreeIPA。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装必要的依赖：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。您可以使用以下命令来安装这些依赖项：\n```\nsudo yum install epel-release\nsudo yum install \\\n    gcc make \\\n    python3-devel \\\n    krb5-devel \\\n    krb5-server \\\n    krb5-libs \\\n    krb5-workstation \\\n    389-ds-base \\\n    389-ds \\\n    libselinux-python \\\n    libsemanage-python \\\n    lib389\n```\n\n3. 在FreeIPA源代码目录中运行安装脚本：\n进入下载的FreeIPA源代码目录，并运行安装脚本进行安装：\n```\ncd freeipa\npython3 ./install/requires\npython3 ./install/genspec\npython3 ./install/bootstrap\n```\n\n4. 编译和安装FreeIPA：\n继续运行以下命令来编译和安装FreeIPA：\n```\ncd build\nmake\nsudo make install\n```\n\n5. 配置和启动FreeIPA服务器：\n运行以下命令来配置和启动FreeIPA服务器：\n```\nipa-server-install\n```\n\n6. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n7. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或访问它们的社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'user', 'content': 'freeipa源码安装'}, {'role': 'assistant', 'content': '要从源代码安装FreeIPA，您可以按照以下步骤进行操作：\n\n1. 下载FreeIPA的源代码：\n您可以从FreeIPA的官方Git仓库中下载最新的源代码。使用以下命令进行下载：\n```\ngit clone https://github.com/freeipa/freeipa.git\n```\n\n2. 安装依赖项：\n在安装FreeIPA之前，您需要安装一些必要的依赖软件包。可以根据您的系统环境运行以下命令：\n```\nsudo yum install -y epel-release\nsudo yum install -y @development-tools\nsudo yum install -y python3-devel python3-cffi python3-gssapi python3-libipa_hbac python3-netifaces python3-pyOpenSSL\n```\n\n3. 配置和安装FreeIPA：\n进入下载的FreeIPA源代码目录，运行以下命令进行配置和安装：\n```\ncd freeipa\nmake\nsudo make install\n```\n\n4. 初始化FreeIPA服务器：\n运行以下命令以初始化FreeIPA服务器：\n```\nsudo ipa-server-install\n```\n\n5. 配置FreeIPA服务器：\n按照安装向导的指示进行配置，包括域名、管理员密码、Kerberos Realm等信息。\n\n6. 启动FreeIPA服务：\n启动FreeIPA服务并设置开机启动：\n```\nsudo systemctl start ipa\nsudo systemctl enable ipa\n```\n\n7. 访问FreeIPA的管理界面：\n使用Web浏览器访问FreeIPA的管理界面：\n```\nhttps://your_server_ip/ipa/ui\n```\n\n8. 使用管理员用户名和密码登录，开始管理用户、组、主机等身份和访问控制信息。\n\n希望以上步骤能帮助您成功从源代码安装FreeIPA。如果遇到任何问题，请参考FreeIPA的官方文档或社区论坛进行寻求帮助。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': '请问您需要关于FreeIPA的信息还是有其他问题需要帮助的呢？'}, {'role': 'user', 'content': '前者'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，提供集中管理用户、组、主机、权限和安全策略的功能。它结合了多个开源项目，如LDAP、Kerberos、DNS等，为组织提供了一个完整的身份和访问管理平台。以下是FreeIPA的一些主要特点和功能：\n\n1. 用户管理：可以在FreeIPA中集中管理用户的帐户信息、权限和访问控制。管理员可以创建、编辑和删除用户帐户，并设置访问策略。\n\n2. 组管理：可以创建和管理组，将用户分组以方便管理和分配权限。\n\n3. 主机管理：可以将主机（包括服务器和客户端）注册到FreeIPA服务中，从而实现对主机的集中管理。\n\n4. 安全认证：FreeIPA集成了Kerberos身份认证系统，提供安全的身份验证机制，确保用户安全地访问系统资源。\n\n5. 证书管理：支持证书颁发机构（CA）和数字证书管理，为系统和应用程序提供安全的通信和身份验证支持。\n\n6. 多因素认证：支持多种认证方法，包括密码、OTP（一次性密码）、智能卡等，提高系统安全性。\n\n7. 访问审计：可以监控和审计用户访问系统资源的行为，帮助管理员了解系统使用情况，发现潜在的安全问题。\n\n总的来说，FreeIPA是一个功能强大、灵活且安全的身份管理解决方案，适用于中小型组织和企业，提供了一站式的身份和访问管理平台。'}, {'role': 'user', 'content': 'Kerberos身份认证系统'}, {'role': 'assistant', 'content': 'Kerberos是一个网络认证协议，最初由麻省理工学院（MIT）开发，旨在提供网络中用户和服务之间的安全认证。Kerberos基于对称密钥加密技术，使用密钥分发中心（KDC）来颁发票据，实现了身份验证和安全通信。以下是Kerberos身份认证系统的一些基本原理和特点：\n\n1. 认证过程：在Kerberos系统中，客户端和服务端之间的认证过程包括三个步骤：认证请求、票据颁发和票据交换。客户端通过KDC获得票据，然后使用票据与服务端进行通信。\n\n2. 对称密钥加密：Kerberos使用对称密钥加密算法（如DES或AES）进行票据的加密和解密，确保通信的机密性和完整性。\n\n3. 单点登录：用户一旦通过Kerberos认证，可以在整个网络中使用同一个身份证书（票据）来访问多个服务，实现了单点登录的便利性。\n\n4. 安全性：由于Kerberos使用密钥分发中心颁发票据，因此避免了明文传输用户密码的安全风险，提高了系统安全性。\n\n5. 可扩展性：Kerberos支持多种认证机制和令牌类型，可以集成到不同的操作系统和应用程序中，实现跨平台和跨应用的身份验证功能。\n\n6. 容错性：Kerberos在票据颁发和验证时采用时间戳和序列号等机制，以确保通信的一致性和可靠性。\n\n总的来说，Kerberos身份认证系统是一种安全可靠的网络认证协议，通过对称密钥加密和票据交换实现用户和服务之间的安全通信。它被广泛应用于企业和组织的网络环境中，提供了强大的身份认证和访问控制功能。'}, {'role': 'user', 'content': '他的原理是什么'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:34:28,435 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:34:28,459 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AD4AF0>
2024-03-22 15:34:28,461 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:34:28,464 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:34:28,466 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:34:28,469 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:34:28,474 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:34:28,477 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:34:28,479 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F1C515E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:34:29,198 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F1C5AD4B20>
2024-03-22 15:34:29,201 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:34:29,205 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:34:29,211 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:34:29,217 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:34:29,221 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:34:45,323 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:34:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'14817'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'191'), (b'x-ratelimit-remaining-tokens', b'38167'), (b'x-ratelimit-reset-requests', b'59m10.625s'), (b'x-ratelimit-reset-tokens', b'2.749s'), (b'x-request-id', b'req_c6ad9abc00e272b6fa39bdfb280308d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Dgxokb14II3LReE.Ukfbn_09xLRcooPMKqpCDqIjqXI-1711092882-1.0.1.1-DLowYcoEPTrWnFvE00LxMkY_vJxjxfzYVLBi83H9lVIfiI7TvNOVsQ6GX9oXowD6aDckVj8cwWcCxR01b_he6A; path=/; expires=Fri, 22-Mar-24 08:04:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fmf1YtD5hBRCw2cFK5AELfgJXXm.UTVeE0JqCgS4RjE-1711092882971-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86847fd4bd91f1fa-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:34:45,330 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:34:45,333 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:34:45,338 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:34:45,342 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:34:45,345 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:34:45,348 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:34:45,364 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:34:45] "GET /user/register?message=他的原理是什么 HTTP/1.1" 200 -
2024-03-22 15:35:30,242 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\apps\\user\\resource.py', reloading
2024-03-22 15:35:30,335 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:35:31,325 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:35:31,327 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:35:31,336 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:35:31,337 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:35:31,346 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:35:31,347 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:35:31,371 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:35:31,376 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:35:31,461 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:35:34,418 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:35:34] "DELETE /user/register?message=freeipa源码安装 HTTP/1.1" 200 -
2024-03-22 15:35:49,288 ERROR [resource.py]: 15 - get - error
2024-03-22 15:35:49,291 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:35:49,295 INFO [resource.py]: 17 - get - info
2024-03-22 15:35:49,309 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '他的原理是什么'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:35:49,387 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:35:49,392 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102605B0>
2024-03-22 15:35:49,395 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:35:49,398 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:35:49,401 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:35:49,403 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:35:49,406 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:35:49,409 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:35:49,412 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FD1011E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:35:50,195 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102605E0>
2024-03-22 15:35:50,202 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:35:50,209 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:35:50,215 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:35:50,219 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:35:50,221 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:35:51,598 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:35:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'792'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'190'), (b'x-ratelimit-remaining-tokens', b'39977'), (b'x-ratelimit-reset-requests', b'1h5m1.729s'), (b'x-ratelimit-reset-tokens', b'34ms'), (b'x-request-id', b'req_45e7b3c82e578d30a01783c929600833'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v.doL7Z_XAulbLWR9a8lAfeob5AHBVsVE.b.vSPok4c-1711092949-1.0.1.1-R67oQfWBBVtwmevpD2._7d8TAeHMWEml25CB_47GvL.G4Uau.bho0AJ9_kRXfXLfJwZwrLPQb_yrTFOupifxEA; path=/; expires=Fri, 22-Mar-24 08:05:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=yOVquWSDSdVwLLrsFnuad3L_pa2iTL8jhL22aWNJM7Q-1711092949349-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868481cf0dddf230-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:35:51,603 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:35:51,607 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:35:51,611 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:35:51,614 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:35:51,620 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:35:51,625 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:35:51,655 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:35:51] "GET /user/register?message=他的原理是什么 HTTP/1.1" 200 -
2024-03-22 15:38:18,238 ERROR [resource.py]: 15 - get - error
2024-03-22 15:38:18,240 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:38:18,241 INFO [resource.py]: 17 - get - info
2024-03-22 15:38:18,247 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': '很抱歉，我无法回答你的问题。你能提供更多上下文信息吗？我希机能更好地理解你的问题。'}, {'role': 'user', 'content': '他的原理是什么'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:38:18,249 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:38:18,251 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102903A0>
2024-03-22 15:38:18,251 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:18,252 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:18,254 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:38:18,255 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:18,256 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:18,257 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:38:18,258 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FD1011E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:38:18,984 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD10261420>
2024-03-22 15:38:18,984 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:38:18,986 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:18,986 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:38:18,987 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:18,988 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:38:20,727 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:38:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'1101'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'190'), (b'x-ratelimit-remaining-tokens', b'39939'), (b'x-ratelimit-reset-requests', b'1h9m44.957s'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'req_41131355841d041c8dada7fa00d08e08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86848570dbf5f234-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:38:20,729 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:38:20,730 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:38:20,730 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:38:20,731 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:38:20,732 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:38:20,733 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:38:20,739 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:38:20] "GET /user/register?message=他的原理是什么 HTTP/1.1" 200 -
2024-03-22 15:38:35,304 ERROR [resource.py]: 15 - get - error
2024-03-22 15:38:35,305 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:38:35,306 INFO [resource.py]: 17 - get - info
2024-03-22 15:38:35,313 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': '很抱歉，我无法回答你的问题。你能提供更多上下文信息吗？我希机能更好地理解你的问题。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': '请问您是在谈论哪个具体的事件、事物或者理论？能否提供更多的背景信息，以便我能够回答您的问题？感谢您的配合。'}, {'role': 'user', 'content': 'freeipa'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:38:35,314 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:38:35,315 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102A00A0>
2024-03-22 15:38:35,316 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:35,317 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:35,318 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:38:35,318 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:35,320 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:35,320 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:38:35,321 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FD1011E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:38:36,390 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102A00D0>
2024-03-22 15:38:36,391 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:38:36,392 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:36,393 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:38:36,393 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:36,394 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:38:43,827 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:38:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'6869'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'189'), (b'x-ratelimit-remaining-tokens', b'39896'), (b'x-ratelimit-reset-requests', b'1h16m39.557s'), (b'x-ratelimit-reset-tokens', b'156ms'), (b'x-request-id', b'req_958848da12ebfe642580c7d68264cf6f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=B0X2h9UbnIArnF2WOCwJls4zR8.HvookALp7Agf0hDQ-1711093121-1.0.1.1-ZhDklayiUgnIY31XgQVkoY7V.BJOErBjARQh7haR1D1icryXHNTvMPsVjHqb9Hpd0p5HSDneK8tTRSqwRaBJ4Q; path=/; expires=Fri, 22-Mar-24 08:08:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=PEYN7W0wVsRCAmdu2WVUJsFrSvpb0zyQa8LVSkKeR7g-1711093121582-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868485ddac78f1d0-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:38:43,829 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:38:43,829 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:38:43,830 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:38:43,831 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:38:43,832 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:38:43,832 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:38:43,837 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:38:43] "GET /user/register?message=freeipa HTTP/1.1" 200 -
2024-03-22 15:38:56,261 ERROR [resource.py]: 15 - get - error
2024-03-22 15:38:56,262 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:38:56,262 INFO [resource.py]: 17 - get - info
2024-03-22 15:38:56,272 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': '很抱歉，我无法回答你的问题。你能提供更多上下文信息吗？我希机能更好地理解你的问题。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': '请问您是在谈论哪个具体的事件、事物或者理论？能否提供更多的背景信息，以便我能够回答您的问题？感谢您的配合。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，它基于LDAP技术和Kerberos认证机制。其原理是通过集成LDAP目录服务、Kerberos认证、DNS服务和Certificate Authority等功能，为组织提供一种集中管理和保护身份及访问控制的解决方案。FreeIPA可以帮助管理员管理用户、组、主机等对象的身份和权限，保护系统资源的安全性，实现统一的身份认证和访问控制管理。'}, {'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:38:56,274 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:38:56,275 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102A2BC0>
2024-03-22 15:38:56,276 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:56,277 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:56,278 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:38:56,279 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:56,279 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:38:56,280 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:38:56,281 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001FD1011E240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:38:57,017 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FD102A2BF0>
2024-03-22 15:38:57,018 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:38:57,019 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:38:57,020 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:38:57,021 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:38:57,021 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:39:04,309 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:39:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'6612'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'188'), (b'x-ratelimit-remaining-tokens', b'39776'), (b'x-ratelimit-reset-requests', b'1h23m30.938s'), (b'x-ratelimit-reset-tokens', b'336ms'), (b'x-request-id', b'req_2db6ff6c3b5b630e9764388c9365e649'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pLOcJkrTPtxKbqBhjgZsgYetR01DFGfEYF7RdCY_nqk-1711093142-1.0.1.1-F6hQNzhrofQZxEhLDicmhCi6bErm3qxdI9ireAth1qbVx1DL4yUcgNTZI.DeQ7QL_kYmUxYAuK6CcSzRvZDddw; path=/; expires=Fri, 22-Mar-24 08:09:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=.ZqjV0rl1Fo_GE_ge60.6CMZ3JAD1.Jy3uH5obWbDKE-1711093142053-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8684865e8902f1dc-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:39:04,310 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:39:04,310 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:39:04,312 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:39:04,312 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:39:04,313 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:39:04,314 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:39:04,319 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:39:04] "GET /user/register?message=freeipa%20linux安装 HTTP/1.1" 200 -
2024-03-22 15:39:08,329 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:39:08,331 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:39:08,361 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:39:09,422 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:39:09,424 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:39:09,450 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:39:09,455 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:39:09,539 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:39:11,501 ERROR [resource.py]: 15 - get - error
2024-03-22 15:39:11,502 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:39:11,502 INFO [resource.py]: 17 - get - info
2024-03-22 15:39:11,507 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:11,563 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:16,595 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:16,596 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:16,600 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 15:39:16,601 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.824277 seconds
2024-03-22 15:39:17,441 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:17,441 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:22,502 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:22,503 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:22,504 DEBUG [_base_client.py]: 1004 - _retry_request - 0 retries left
2024-03-22 15:39:22,505 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 1.701540 seconds
2024-03-22 15:39:24,214 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:24,215 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:29,229 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:29,229 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:29,231 DEBUG [_base_client.py]: 936 - _request - Raising timeout error
2024-03-22 15:39:29,298 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:39:29] "[35m[1mGET /user/register?message=freeipa%20linux安装 HTTP/1.1[0m" 500 -
2024-03-22 15:39:33,165 ERROR [resource.py]: 15 - get - error
2024-03-22 15:39:33,166 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:39:33,167 INFO [resource.py]: 17 - get - info
2024-03-22 15:39:33,172 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:33,173 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:38,177 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:38,178 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:38,179 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 15:39:38,180 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.793382 seconds
2024-03-22 15:39:38,978 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:38,978 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:43,988 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:43,989 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:43,990 DEBUG [_base_client.py]: 1004 - _retry_request - 0 retries left
2024-03-22 15:39:43,991 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 1.982141 seconds
2024-03-22 15:39:45,986 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:39:45,987 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:39:50,997 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-03-22 15:39:50,998 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-03-22 15:39:50,999 DEBUG [_base_client.py]: 936 - _request - Raising timeout error
2024-03-22 15:39:51,061 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:39:51] "[35m[1mGET /user/register?message=freeipa%20linux安装 HTTP/1.1[0m" 500 -
2024-03-22 15:41:09,009 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:09,011 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:09,020 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:09,021 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:09,030 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:09,031 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:09,060 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-03-22 15:41:10,023 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:10,025 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:10,034 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:10,035 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:10,044 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-03-22 15:41:10,044 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-03-22 15:41:10,068 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-03-22 15:41:10,073 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 137-291-541
2024-03-22 15:41:10,157 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-03-22 15:41:13,841 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:41:13] "DELETE /user/register?message=freeipa%20linux安装 HTTP/1.1" 200 -
2024-03-22 15:41:18,377 ERROR [resource.py]: 15 - get - error
2024-03-22 15:41:18,381 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:41:18,385 INFO [resource.py]: 17 - get - info
2024-03-22 15:41:18,407 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:41:18,493 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:41:18,498 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A69405B0>
2024-03-22 15:41:18,500 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:18,504 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:41:18,506 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:41:18,508 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:41:18,511 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:18,513 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:41:18,517 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:41:18,714 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))
2024-03-22 15:41:18,720 DEBUG [_base_client.py]: 939 - _request - Encountered Exception
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)
2024-03-22 15:41:18,748 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 15:41:18,752 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.899539 seconds
2024-03-22 15:41:19,658 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:41:19,664 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:41:19,672 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6941690>
2024-03-22 15:41:19,674 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:19,677 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:41:19,678 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:41:19,681 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:41:19,684 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:19,687 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:41:19,690 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:41:20,396 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A69416C0>
2024-03-22 15:41:20,400 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:41:20,406 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:41:20,409 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:41:20,414 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:41:20,417 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:41:27,051 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:41:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5972'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'187'), (b'x-ratelimit-remaining-tokens', b'39978'), (b'x-ratelimit-reset-requests', b'1h28m19.532s'), (b'x-ratelimit-reset-tokens', b'33ms'), (b'x-request-id', b'req_9638da4aecede816a4afd62078a0a7cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GwAKcj5bVBOozSkmvfJlewcOU5K9mVnt5FKaGjW_vwM-1711093284-1.0.1.1-V.QVzB4vUcmh4xorpOMK1r4oCaapZIHnUYl58ktA1AGwq5aUycoadXRx6NVc7.B74oxS2gtdbyrGiIQQbxtd0Q; path=/; expires=Fri, 22-Mar-24 08:11:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BZkAoVh.FsvLukCt4GQnUwBs.9l2fcoygAnB4Xf68HQ-1711093284810-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868489deca95f1f4-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:41:27,056 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:41:27,058 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:41:27,061 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:41:27,063 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:41:27,066 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:41:27,071 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:41:27,103 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:41:27] "GET /user/register?message=freeipa%20linux安装 HTTP/1.1" 200 -
2024-03-22 15:41:53,582 ERROR [resource.py]: 15 - get - error
2024-03-22 15:41:53,583 DEBUG [resource.py]: 16 - get - debug
2024-03-22 15:41:53,584 INFO [resource.py]: 17 - get - info
2024-03-22 15:41:53,589 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 15:41:53,590 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 15:41:53,592 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6943E50>
2024-03-22 15:41:53,592 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:53,593 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:41:53,594 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 15:41:53,594 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:41:53,594 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 15:41:53,595 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 15:41:53,596 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 15:41:54,300 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A04190>
2024-03-22 15:41:54,300 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 15:41:54,301 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 15:41:54,302 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 15:41:54,303 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 15:41:54,303 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 15:42:00,616 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 07:41:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5512'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'186'), (b'x-ratelimit-remaining-tokens', b'39690'), (b'x-ratelimit-reset-requests', b'1h34m57.646s'), (b'x-ratelimit-reset-tokens', b'465ms'), (b'x-request-id', b'req_59b4209dbc73f5a5dffb4b75d2f10ee0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.x7ZE_Baqr00sWr58XYa83HorWOCT89i.SDe22Jn_iM-1711093318-1.0.1.1-uOmRRzdP3LNkNgAPAs70HcDytiCjsTA2KlJQ69_9LLli9A2u6rqxxq3lRRvQhh49BqyoBsWuYNw9L8AMMkM5.Q; path=/; expires=Fri, 22-Mar-24 08:11:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hyJYFfMAFLQtYZrfMYsp09QWCA7atrUHdzUEoT3MftY-1711093318369-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86848ab28cfcf1ec-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 15:42:00,617 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 15:42:00,617 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 15:42:00,618 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 15:42:00,619 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 15:42:00,619 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 15:42:00,620 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 15:42:00,629 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 15:42:00] "GET /user/register?message=他的原理是什么 HTTP/1.1" 200 -
2024-03-22 17:04:09,058 ERROR [resource.py]: 15 - get - error
2024-03-22 17:04:09,070 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:04:09,075 INFO [resource.py]: 17 - get - info
2024-03-22 17:04:09,139 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:04:09,169 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:04:09,177 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A105E0>
2024-03-22 17:04:09,181 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:04:09,187 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:04:09,191 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:04:09,193 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:04:09,196 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:04:09,201 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:04:09,205 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:04:09,390 DEBUG [_trace.py]: 45 - trace - start_tls.failed exception=ConnectError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)'))
2024-03-22 17:04:09,399 DEBUG [_base_client.py]: 939 - _request - Encountered Exception
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http_proxy.py", line 317, in handle_request
    stream = stream.start_tls(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\http11.py", line 383, in start_tls
    return self._stream.start_tls(ssl_context, server_hostname, timeout)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 152, in start_tls
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: EOF occurred in violation of protocol (_ssl.c:997)
2024-03-22 17:04:09,409 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-03-22 17:04:09,411 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.782089 seconds
2024-03-22 17:04:10,201 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:04:10,205 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:04:10,231 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A04F10>
2024-03-22 17:04:10,235 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:04:10,240 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:04:10,243 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:04:10,248 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:04:10,251 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:04:10,255 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:04:10,258 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:04:11,004 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A04E20>
2024-03-22 17:04:11,016 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:04:11,025 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:04:11,028 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:04:11,034 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:04:11,036 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:04:19,890 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:04:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'7964'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'195'), (b'x-ratelimit-remaining-tokens', b'39385'), (b'x-ratelimit-reset-requests', b'34m16.88s'), (b'x-ratelimit-reset-tokens', b'922ms'), (b'x-request-id', b'req_930826783c80d6d5d220889d7cd39ee8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AmdtPz0zKpio9sL6j0tBcFpkXqUNXBpscSiD7fkvp0M-1711098257-1.0.1.1-j.Vb3aE6z5VAGcaazfmNWMNHVEuuTE7SIjPFutF.nzfvVvkHWV5bSBkPtBKqBazFZiN2IFMTTomwCJvM3KHBrQ; path=/; expires=Fri, 22-Mar-24 09:34:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868503393cf0f1d0-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:04:19,896 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:04:19,902 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:04:19,910 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:04:19,916 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:04:19,921 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:04:19,924 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:04:19,989 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:04:19] "GET /user/register?message=用python开发一个gpt软件 HTTP/1.1" 200 -
2024-03-22 17:06:06,951 ERROR [resource.py]: 15 - get - error
2024-03-22 17:06:06,953 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:06:06,954 INFO [resource.py]: 17 - get - info
2024-03-22 17:06:06,964 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python来开发一个GPT（生成式预训练）软件，可以借助开源的GPT-2或GPT-3模型，如OpenAI的GPT模型，通过Python编程来实现文本生成的功能。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装相关库：\n```bash\npip install transformers torch\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的GPT-2模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained(\'gpt2\')\ntokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n```\n\n4. 定义一个生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 调用生成文本的函数并输出结果：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt)\nprint(generated_text)\n```\n\n这段代码会使用预训练的GPT-2模型根据给定的起始文本生成接下来的文本。通过修改prompt和max_length参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际上开发一个完整的GPT软件还需要考虑模型训练、性能优化、用户界面设计等方面。建议在开发之前先了解GPT模型的原理和使用方法，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': 'freeipa'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:06:06,969 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:06:06,970 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A1C0A0>
2024-03-22 17:06:06,972 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:06:06,973 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:06:06,974 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:06:06,975 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:06:06,976 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:06:06,976 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:06:06,977 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:06:07,696 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A1C0D0>
2024-03-22 17:06:07,697 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:06:07,698 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:06:07,699 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:06:07,700 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:06:07,701 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:06:22,497 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:06:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'14167'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'194'), (b'x-ratelimit-remaining-tokens', b'38994'), (b'x-ratelimit-reset-requests', b'39m32.229s'), (b'x-ratelimit-reset-tokens', b'1.509s'), (b'x-request-id', b'req_816f5111b651f56c6aaaee9e35fb3a4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=949_35KgfVcy6mBKtwd6mozUOMeft92KD2xnNgJB9.M-1711098380-1.0.1.1-GnnadDAl18fmyZTMtPnJI4zdrXGspBM.euMYFQuY9ni08C5qdLUI74Tndj.OyOv1OUvq7fTBXbhvJdLSY8fbUw; path=/; expires=Fri, 22-Mar-24 09:36:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=h.Y5SX8n0Ge41bCTTAZOh4xcJEBftWhovP.Rn5pDYww-1711098380264-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868506125e9df228-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:06:22,500 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:06:22,501 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:06:22,502 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:06:22,502 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:06:22,503 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:06:22,505 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:06:22,517 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:06:22] "GET /user/register?message=freeipa HTTP/1.1" 200 -
2024-03-22 17:06:26,908 ERROR [resource.py]: 15 - get - error
2024-03-22 17:06:26,908 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:06:26,910 INFO [resource.py]: 17 - get - info
2024-03-22 17:06:26,925 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python来开发一个GPT（生成式预训练）软件，可以借助开源的GPT-2或GPT-3模型，如OpenAI的GPT模型，通过Python编程来实现文本生成的功能。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装相关库：\n```bash\npip install transformers torch\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的GPT-2模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained(\'gpt2\')\ntokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n```\n\n4. 定义一个生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 调用生成文本的函数并输出结果：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt)\nprint(generated_text)\n```\n\n这段代码会使用预训练的GPT-2模型根据给定的起始文本生成接下来的文本。通过修改prompt和max_length参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际上开发一个完整的GPT软件还需要考虑模型训练、性能优化、用户界面设计等方面。建议在开发之前先了解GPT模型的原理和使用方法，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，它结合了LDAP目录服务、Kerberos认证和DNS等技术，旨在提供集中式身份管理、认证和授权服务。下面是一些 FreeIPA 的功能：\n\n1. 用户和组管理：可以在 FreeIPA 中管理用户和组，包括创建、删除、修改用户信息等操作。用户可以通过用户名和密码认证登录系统，并被分配到不同的用户组。\n\n2. 主机管理：FreeIPA 允许管理主机或服务器的身份信息，包括主机名称和密钥等信息。这些信息可以用于检查主机的身份并进行身份验证。\n\n3. 策略和权限管理：通过 FreeIPA 可以设置访问控制策略和权限，例如限制用户访问特定资源、定义密码策略等。\n\n4. Kerberos身份认证：FreeIPA 使用 Kerberos 提供安全的身份认证机制，用户可以使用 Kerberos ticket 进行单点登录。\n\n5. 集中式认证和授权服务：FreeIPA 提供一个集中式的认证和授权服务，可以管理整个组织中的用户和系统，从而提高安全性和管理效率。\n\n6. 证书管理：FreeIPA 包括一个 CA（证书颁发机构），可以管理数字证书并确保数据传输的安全性。\n\n总的来说，FreeIPA 提供了一个综合的身份管理解决方案，涵盖了用户管理、组管理、主机管理、认证、授权、密码策略等方面。这些功能使得 FreeIPA 成为组织中实现身份管理和安全的有力工具。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:06:26,931 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:06:26,933 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:06:26,934 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:06:26,935 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:06:26,936 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:06:47,760 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:06:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'20181'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'193'), (b'x-ratelimit-remaining-tokens', b'38617'), (b'x-ratelimit-reset-requests', b'46m24.949s'), (b'x-ratelimit-reset-tokens', b'2.074s'), (b'x-request-id', b'req_e3bbff3005d3144180f3d6693d5d8c73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8685068a98b2f228-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:06:47,768 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:06:47,771 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:06:47,780 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:06:47,784 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:06:47,791 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:06:47,798 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:06:47,836 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:06:47] "GET /user/register?message=用python开发一个gpt软件 HTTP/1.1" 200 -
2024-03-22 17:07:42,492 ERROR [resource.py]: 15 - get - error
2024-03-22 17:07:42,496 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:07:42,499 INFO [resource.py]: 17 - get - info
2024-03-22 17:07:42,545 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python来开发一个GPT（生成式预训练）软件，可以借助开源的GPT-2或GPT-3模型，如OpenAI的GPT模型，通过Python编程来实现文本生成的功能。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装相关库：\n```bash\npip install transformers torch\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的GPT-2模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained(\'gpt2\')\ntokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n```\n\n4. 定义一个生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 调用生成文本的函数并输出结果：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt)\nprint(generated_text)\n```\n\n这段代码会使用预训练的GPT-2模型根据给定的起始文本生成接下来的文本。通过修改prompt和max_length参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际上开发一个完整的GPT软件还需要考虑模型训练、性能优化、用户界面设计等方面。建议在开发之前先了解GPT模型的原理和使用方法，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，它结合了LDAP目录服务、Kerberos认证和DNS等技术，旨在提供集中式身份管理、认证和授权服务。下面是一些 FreeIPA 的功能：\n\n1. 用户和组管理：可以在 FreeIPA 中管理用户和组，包括创建、删除、修改用户信息等操作。用户可以通过用户名和密码认证登录系统，并被分配到不同的用户组。\n\n2. 主机管理：FreeIPA 允许管理主机或服务器的身份信息，包括主机名称和密钥等信息。这些信息可以用于检查主机的身份并进行身份验证。\n\n3. 策略和权限管理：通过 FreeIPA 可以设置访问控制策略和权限，例如限制用户访问特定资源、定义密码策略等。\n\n4. Kerberos身份认证：FreeIPA 使用 Kerberos 提供安全的身份认证机制，用户可以使用 Kerberos ticket 进行单点登录。\n\n5. 集中式认证和授权服务：FreeIPA 提供一个集中式的认证和授权服务，可以管理整个组织中的用户和系统，从而提高安全性和管理效率。\n\n6. 证书管理：FreeIPA 包括一个 CA（证书颁发机构），可以管理数字证书并确保数据传输的安全性。\n\n总的来说，FreeIPA 提供了一个综合的身份管理解决方案，涵盖了用户管理、组管理、主机管理、认证、授权、密码策略等方面。这些功能使得 FreeIPA 成为组织中实现身份管理和安全的有力工具。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python开发一个基于GPT（生成式预训练）模型的文本生成软件，可以使用Hugging Face Transformers库，这是一个开源的库，提供了大量预训练的自然语言处理模型（包括GPT模型），并提供了简单易用的API来使用这些模型。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装 transformers 库：\n```bash\npip install transformers\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的 GPT-2 模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained("gpt2")\ntokenizer = GPT2Tokenizer.from_pretrained("gpt2")\n```\n\n4. 定义生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 使用生成文本的函数：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt, max_length=200)\nprint(generated_text)\n```\n\n这段代码会使用预训练的 GPT-2 模型根据给定的起始文本生成接下来的文本。通过修改 prompt 和 max_length 参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际开发一个完整的 GPT 软件可能涉及更复杂的功能和交互界面。建议在开发之前先了解 GPT 模型的原理和如何使用 Transformers 库，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': '如果是gpt3ne'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:07:42,564 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:07:42,569 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A29600>
2024-03-22 17:07:42,573 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:07:42,578 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:07:42,582 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:07:42,588 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:07:42,593 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:07:42,597 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:07:42,601 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:07:43,363 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A287C0>
2024-03-22 17:07:43,368 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:07:43,372 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:07:43,376 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:07:43,379 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:07:43,383 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:07:50,144 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:07:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'5871'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'192'), (b'x-ratelimit-remaining-tokens', b'38190'), (b'x-ratelimit-reset-requests', b'52m20.48s'), (b'x-ratelimit-reset-tokens', b'2.715s'), (b'x-request-id', b'req_5c5ef3018a46de920464dda177c74be7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TZsjYx4U7FhRmyYV5hyZ3nHJ7RQy08Id4YO3sXXqyLA-1711098467-1.0.1.1-YfcsGrgluXI4h.tP63qac2kJ6nlMFDffpkN7UMezFGHF0edI6UXaCKOcoNRE34RJR3FYw248BgNW.hoefYnE5g; path=/; expires=Fri, 22-Mar-24 09:37:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IVIE7HV_GUqrhKztQH56gwFByWIy9JGSL9YpKcPkcbs-1711098467900-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'868508686c7bf1bc-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:07:50,152 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:07:50,159 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:07:50,167 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:07:50,169 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:07:50,171 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:07:50,174 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:07:50,197 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:07:50] "GET /user/register?message=如果是gpt3ne HTTP/1.1" 200 -
2024-03-22 17:08:23,937 ERROR [resource.py]: 15 - get - error
2024-03-22 17:08:23,942 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:08:23,946 INFO [resource.py]: 17 - get - info
2024-03-22 17:08:24,043 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python来开发一个GPT（生成式预训练）软件，可以借助开源的GPT-2或GPT-3模型，如OpenAI的GPT模型，通过Python编程来实现文本生成的功能。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装相关库：\n```bash\npip install transformers torch\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的GPT-2模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained(\'gpt2\')\ntokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n```\n\n4. 定义一个生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 调用生成文本的函数并输出结果：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt)\nprint(generated_text)\n```\n\n这段代码会使用预训练的GPT-2模型根据给定的起始文本生成接下来的文本。通过修改prompt和max_length参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际上开发一个完整的GPT软件还需要考虑模型训练、性能优化、用户界面设计等方面。建议在开发之前先了解GPT模型的原理和使用方法，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，它结合了LDAP目录服务、Kerberos认证和DNS等技术，旨在提供集中式身份管理、认证和授权服务。下面是一些 FreeIPA 的功能：\n\n1. 用户和组管理：可以在 FreeIPA 中管理用户和组，包括创建、删除、修改用户信息等操作。用户可以通过用户名和密码认证登录系统，并被分配到不同的用户组。\n\n2. 主机管理：FreeIPA 允许管理主机或服务器的身份信息，包括主机名称和密钥等信息。这些信息可以用于检查主机的身份并进行身份验证。\n\n3. 策略和权限管理：通过 FreeIPA 可以设置访问控制策略和权限，例如限制用户访问特定资源、定义密码策略等。\n\n4. Kerberos身份认证：FreeIPA 使用 Kerberos 提供安全的身份认证机制，用户可以使用 Kerberos ticket 进行单点登录。\n\n5. 集中式认证和授权服务：FreeIPA 提供一个集中式的认证和授权服务，可以管理整个组织中的用户和系统，从而提高安全性和管理效率。\n\n6. 证书管理：FreeIPA 包括一个 CA（证书颁发机构），可以管理数字证书并确保数据传输的安全性。\n\n总的来说，FreeIPA 提供了一个综合的身份管理解决方案，涵盖了用户管理、组管理、主机管理、认证、授权、密码策略等方面。这些功能使得 FreeIPA 成为组织中实现身份管理和安全的有力工具。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python开发一个基于GPT（生成式预训练）模型的文本生成软件，可以使用Hugging Face Transformers库，这是一个开源的库，提供了大量预训练的自然语言处理模型（包括GPT模型），并提供了简单易用的API来使用这些模型。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装 transformers 库：\n```bash\npip install transformers\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的 GPT-2 模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained("gpt2")\ntokenizer = GPT2Tokenizer.from_pretrained("gpt2")\n```\n\n4. 定义生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 使用生成文本的函数：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt, max_length=200)\nprint(generated_text)\n```\n\n这段代码会使用预训练的 GPT-2 模型根据给定的起始文本生成接下来的文本。通过修改 prompt 和 max_length 参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际开发一个完整的 GPT 软件可能涉及更复杂的功能和交互界面。建议在开发之前先了解 GPT 模型的原理和如何使用 Transformers 库，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': '如果是gpt3ne'}, {'role': 'assistant', 'content': '使用OpenAI的 GPT-3 模型进行文本生成的开发同样可以通过 Hugging Face Transformers 库来实现。由于 GPT-3 模型需要进行 API 调用才能使用，因此在开发过程中需要提前获取 OpenAI 的 API 访问权限。以下是一个简单示例代码来使用 GPT-3 模型进行文本生成：\n\n1. 安装相关库：\n```bash\npip install openai transformers\n```\n\n2. 导入必要的库：\n```python\nimport openai\n```\n\n3. 设置 OpenAI API 密钥：\n```python\nopenai.api_key = "YOUR_API_KEY"\n```\n\n4. 定义生成文本的函数：\n```python\ndef generate_text(prompt, max_tokens=100):\n    response = openai.Completion.create(engine="text-davinci-003", prompt=prompt, max_tokens=max_tokens)\n    generated_text = response.choices[0].text\n    return generated_text\n```\n\n5. 使用生成文本的函数：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt, max_tokens=200)\nprint(generated_text)\n```\n\n在这个示例代码中，我们使用了 OpenAI 的 GPT-3 模型，通过调用 OpenAI 的 API 来生成文本。需要替换 `YOUR_API_KEY` 为您在 OpenAI 上获取的实际 API 密钥，以便进行访问。在调用 `generate_text` 函数时，可以传入不同的 prompt 和 max_tokens 参数来生成不同的文本内容和长度。\n\n需要注意的是，使用 OpenAI 的 GPT-3 模型进行文本生成需要保护您的 API 密钥，并遵守 OpenAI 的使用条款和条件。确保在开发过程中遵循相关指导和安全措施。'}, {'role': 'user', 'content': 'gpt3和gpt3.5的区别'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:08:24,053 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:08:24,058 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A43DF0>
2024-03-22 17:08:24,061 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:08:24,063 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:08:24,066 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:08:24,069 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:08:24,073 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:08:24,076 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:08:24,079 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:08:24,824 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A10880>
2024-03-22 17:08:24,826 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:08:24,830 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:08:24,834 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:08:24,838 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:08:24,840 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:08:32,714 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:08:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'6922'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'191'), (b'x-ratelimit-remaining-tokens', b'37808'), (b'x-ratelimit-reset-requests', b'58m50.961s'), (b'x-ratelimit-reset-tokens', b'3.288s'), (b'x-request-id', b'req_4eaf34ff1d02b0e7f75c551d60786841'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8685096b8e45f255-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:08:32,718 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:08:32,720 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:08:32,723 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:08:32,725 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:08:32,727 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:08:32,731 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:08:32,759 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:08:32] "GET /user/register?message=gpt3和gpt3.5的区别 HTTP/1.1" 200 -
2024-03-22 17:09:29,294 ERROR [resource.py]: 15 - get - error
2024-03-22 17:09:29,297 DEBUG [resource.py]: 16 - get - debug
2024-03-22 17:09:29,300 INFO [resource.py]: 17 - get - info
2024-03-22 17:09:29,372 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'freeipa linux安装'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理系统，在Linux系统上安装FreeIPA可以实现集中化管理用户、组、主机等身份信息。以下是在Linux系统上安装FreeIPA的步骤：\n\n1. 更新系统软件包：\n```\nsudo yum update\n```\n\n2. 安装FreeIPA软件包：\n```\nsudo yum install freeipa-server\n```\n\n3. 运行ipa-server安装向导：\n```\nsudo ipa-server-install\n```\n\n4. 按照安装向导的提示逐步进行配置，包括设置域名、管理员密码、IPA服务器的主机名等。\n\n5. 完成安装后，可以通过Web界面或命令行工具来管理FreeIPA服务器，例如：\n```\nipa user-add alice --first=Alice --last=Smith\n```\n这条命令会创建一个名为Alice的用户。\n\n6. 配置防火墙允许必要的端口：\n```\nsudo firewall-cmd --add-service=freeipa-ldap\nsudo firewall-cmd --add-service=freeipa-ldaps\nsudo firewall-cmd --add-service=freeipa-replication\nsudo firewall-cmd --reload\n```\n\n安装完成后，可以通过访问https://ipa.example.com 来进行管理FreeIPA服务器。在管理界面中，可以添加用户、主机、组等信息，并配置策略和权限。'}, {'role': 'user', 'content': '他的原理是什么'}, {'role': 'assistant', 'content': 'FreeIPA的原理是基于集中式身份管理的概念，通过集中管理用户、组、主机等信息，提供身份验证、授权和访问控制等功能。其主要原理包括以下几个方面：\n\n1. LDAP（轻量级目录访问协议）：FreeIPA使用LDAP作为存储用户、组、主机等身份信息的数据库，通过LDAP将这些信息进行组织和管理，并提供对这些信息的快速访问和查询。\n\n2. Kerberos身份验证：FreeIPA使用Kerberos作为其身份验证协议，实现用户在系统之间的单点登录。用户一旦登录了FreeIPA系统，就可以在该系统上不用再输入密码就可以访问其他系统。\n\n3. DNS名称解析：FreeIPA还包含DNS服务器，用于提供主机名到IP地址的解析服务，确保不同系统能够通过主机名相互访问。\n\n4. CA证书管理：FreeIPA还包含证书颁发机构（CA），用于管理证书和加密通信，确保通信安全性。\n\n综合来说，FreeIPA的工作原理是将各个系统、应用程序和用户的身份信息集中化管理，在集中管理的基础上实现身份认证、授权和访问控制，提供安全、高效的身份管理服务。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python来开发一个GPT（生成式预训练）软件，可以借助开源的GPT-2或GPT-3模型，如OpenAI的GPT模型，通过Python编程来实现文本生成的功能。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装相关库：\n```bash\npip install transformers torch\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的GPT-2模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained(\'gpt2\')\ntokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n```\n\n4. 定义一个生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 调用生成文本的函数并输出结果：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt)\nprint(generated_text)\n```\n\n这段代码会使用预训练的GPT-2模型根据给定的起始文本生成接下来的文本。通过修改prompt和max_length参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际上开发一个完整的GPT软件还需要考虑模型训练、性能优化、用户界面设计等方面。建议在开发之前先了解GPT模型的原理和使用方法，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': 'freeipa'}, {'role': 'assistant', 'content': 'FreeIPA是一个开源的身份管理解决方案，它结合了LDAP目录服务、Kerberos认证和DNS等技术，旨在提供集中式身份管理、认证和授权服务。下面是一些 FreeIPA 的功能：\n\n1. 用户和组管理：可以在 FreeIPA 中管理用户和组，包括创建、删除、修改用户信息等操作。用户可以通过用户名和密码认证登录系统，并被分配到不同的用户组。\n\n2. 主机管理：FreeIPA 允许管理主机或服务器的身份信息，包括主机名称和密钥等信息。这些信息可以用于检查主机的身份并进行身份验证。\n\n3. 策略和权限管理：通过 FreeIPA 可以设置访问控制策略和权限，例如限制用户访问特定资源、定义密码策略等。\n\n4. Kerberos身份认证：FreeIPA 使用 Kerberos 提供安全的身份认证机制，用户可以使用 Kerberos ticket 进行单点登录。\n\n5. 集中式认证和授权服务：FreeIPA 提供一个集中式的认证和授权服务，可以管理整个组织中的用户和系统，从而提高安全性和管理效率。\n\n6. 证书管理：FreeIPA 包括一个 CA（证书颁发机构），可以管理数字证书并确保数据传输的安全性。\n\n总的来说，FreeIPA 提供了一个综合的身份管理解决方案，涵盖了用户管理、组管理、主机管理、认证、授权、密码策略等方面。这些功能使得 FreeIPA 成为组织中实现身份管理和安全的有力工具。'}, {'role': 'user', 'content': '用python开发一个gpt软件'}, {'role': 'assistant', 'content': '要使用Python开发一个基于GPT（生成式预训练）模型的文本生成软件，可以使用Hugging Face Transformers库，这是一个开源的库，提供了大量预训练的自然语言处理模型（包括GPT模型），并提供了简单易用的API来使用这些模型。以下是一个简单的示例代码来使用GPT-2模型生成文本：\n\n1. 安装 transformers 库：\n```bash\npip install transformers\n```\n\n2. 导入必要的库：\n```python\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\n```\n\n3. 加载预训练的 GPT-2 模型和分词器：\n```python\nmodel = GPT2LMHeadModel.from_pretrained("gpt2")\ntokenizer = GPT2Tokenizer.from_pretrained("gpt2")\n```\n\n4. 定义生成文本的函数：\n```python\ndef generate_text(prompt, max_length=100):\n    input_ids = tokenizer.encode(prompt, return_tensors=\'pt\')\n    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    return generated_text\n```\n\n5. 使用生成文本的函数：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt, max_length=200)\nprint(generated_text)\n```\n\n这段代码会使用预训练的 GPT-2 模型根据给定的起始文本生成接下来的文本。通过修改 prompt 和 max_length 参数，可以生成不同的文本内容和长度。\n\n请注意，这只是一个简单的示例代码，实际开发一个完整的 GPT 软件可能涉及更复杂的功能和交互界面。建议在开发之前先了解 GPT 模型的原理和如何使用 Transformers 库，以便更好地实现文本生成功能。'}, {'role': 'user', 'content': '如果是gpt3ne'}, {'role': 'assistant', 'content': '使用OpenAI的 GPT-3 模型进行文本生成的开发同样可以通过 Hugging Face Transformers 库来实现。由于 GPT-3 模型需要进行 API 调用才能使用，因此在开发过程中需要提前获取 OpenAI 的 API 访问权限。以下是一个简单示例代码来使用 GPT-3 模型进行文本生成：\n\n1. 安装相关库：\n```bash\npip install openai transformers\n```\n\n2. 导入必要的库：\n```python\nimport openai\n```\n\n3. 设置 OpenAI API 密钥：\n```python\nopenai.api_key = "YOUR_API_KEY"\n```\n\n4. 定义生成文本的函数：\n```python\ndef generate_text(prompt, max_tokens=100):\n    response = openai.Completion.create(engine="text-davinci-003", prompt=prompt, max_tokens=max_tokens)\n    generated_text = response.choices[0].text\n    return generated_text\n```\n\n5. 使用生成文本的函数：\n```python\nprompt = "Once upon a time"\ngenerated_text = generate_text(prompt, max_tokens=200)\nprint(generated_text)\n```\n\n在这个示例代码中，我们使用了 OpenAI 的 GPT-3 模型，通过调用 OpenAI 的 API 来生成文本。需要替换 `YOUR_API_KEY` 为您在 OpenAI 上获取的实际 API 密钥，以便进行访问。在调用 `generate_text` 函数时，可以传入不同的 prompt 和 max_tokens 参数来生成不同的文本内容和长度。\n\n需要注意的是，使用 OpenAI 的 GPT-3 模型进行文本生成需要保护您的 API 密钥，并遵守 OpenAI 的使用条款和条件。确保在开发过程中遵循相关指导和安全措施。'}, {'role': 'user', 'content': 'gpt3和gpt3.5的区别'}, {'role': 'assistant', 'content': '目前并不存在 "GPT-3.5" 的官方版本，可能是您对 "GPT-3" 有所混淆。以下是 GPT-3 和 GPT-3.5 的区别：\n\n1. GPT-3：\n- GPT-3（Generative Pre-trained Transformer 3）是由 OpenAI 公司开发的第三代生成式预训练模型，具有极其强大的文本生成能力和语言理解能力。\n- GPT-3 拥有1750亿个参数，是目前规模最大的自然语言处理模型之一，能够生成高质量的自然语言文本。\n- GPT-3 被广泛用于各种任务，包括语言模型、文本生成、问答系统、翻译等领域。\n\n2. GPT-3.5（虚拟名称）：\n- "GPT-3.5" 并非一个官方的模型或版本，而是可能被用来指代一个假设的更大规模或者更新版本的 GPT-3 模型。\n- 如果未来 OpenAI 发布了一个更大规模或者改进的 GPT-3 模型，人们可能会使用类似 "GPT-3.5" 的名称来指代这个新版本。\n\n总的来说，GPT-3 是当前 OpenAI 最新发布的一代强大的生成式预训练模型，具有出色的文本生成能力。而 "GPT-3.5" 并非一个官方版本，可能用来描述对 GPT-3 的一种设想或者期望。如果未来出现了新的版本或者更新，相关的名称和描述可能会根据情况而定。'}, {'role': 'user', 'content': 'gpt4'}], 'model': 'gpt-3.5-turbo'}}
2024-03-22 17:09:29,383 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='127.0.0.1' port=17890 local_address=None timeout=5.0 socket_options=None
2024-03-22 17:09:29,390 DEBUG [_trace.py]: 45 - trace - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A43A30>
2024-03-22 17:09:29,394 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:09:29,399 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:09:29,402 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'CONNECT']>
2024-03-22 17:09:29,405 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:09:29,408 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'CONNECT']>
2024-03-22 17:09:29,410 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2024-03-22 17:09:29,413 DEBUG [_trace.py]: 45 - trace - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000144A67FE240> server_hostname='api.openai.com' timeout=5.0
2024-03-22 17:09:30,143 DEBUG [_trace.py]: 45 - trace - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000144A6A46740>
2024-03-22 17:09:30,152 DEBUG [_trace.py]: 45 - trace - send_request_headers.started request=<Request [b'POST']>
2024-03-22 17:09:30,155 DEBUG [_trace.py]: 45 - trace - send_request_headers.complete
2024-03-22 17:09:30,157 DEBUG [_trace.py]: 45 - trace - send_request_body.started request=<Request [b'POST']>
2024-03-22 17:09:30,161 DEBUG [_trace.py]: 45 - trace - send_request_body.complete
2024-03-22 17:09:30,164 DEBUG [_trace.py]: 45 - trace - receive_response_headers.started request=<Request [b'POST']>
2024-03-22 17:09:41,667 DEBUG [_trace.py]: 45 - trace - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 22 Mar 2024 09:09:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'sen-aalluu'), (b'openai-processing-ms', b'10655'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'200'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'190'), (b'x-ratelimit-remaining-tokens', b'37499'), (b'x-ratelimit-reset-requests', b'1h4m57.48s'), (b'x-ratelimit-reset-tokens', b'3.751s'), (b'x-request-id', b'req_d44a421430a5bef58422b5eacae8891a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86850b03ca54f230-KHH'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-03-22 17:09:41,678 INFO [_client.py]: 1026 - _send_single_request - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-03-22 17:09:41,685 DEBUG [_trace.py]: 45 - trace - receive_response_body.started request=<Request [b'POST']>
2024-03-22 17:09:41,690 DEBUG [_trace.py]: 45 - trace - receive_response_body.complete
2024-03-22 17:09:41,694 DEBUG [_trace.py]: 45 - trace - response_closed.started
2024-03-22 17:09:41,700 DEBUG [_trace.py]: 45 - trace - response_closed.complete
2024-03-22 17:09:41,705 DEBUG [_base_client.py]: 954 - _request - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"
2024-03-22 17:09:41,730 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [22/Mar/2024 17:09:41] "GET /user/register?message=gpt4 HTTP/1.1" 200 -
2024-06-17 16:15:08,944 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:15:08,950 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:15:08,975 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-06-17 16:15:09,678 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:15:09,679 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:15:09,696 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-06-17 16:15:09,700 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-06-17 16:15:09,760 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-06-17 16:15:11,327 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:15:11] "[33mGET / HTTP/1.1[0m" 404 -
2024-06-17 16:15:12,070 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:15:12] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-06-17 16:18:02,669 ERROR [resource.py]: 15 - get - error
2024-06-17 16:18:02,670 DEBUG [resource.py]: 16 - get - debug
2024-06-17 16:18:02,670 INFO [resource.py]: 17 - get - info
2024-06-17 16:18:02,674 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': None}], 'model': 'gpt-3.5-turbo'}}
2024-06-17 16:18:02,721 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-06-17 16:18:07,738 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-06-17 16:18:07,740 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-06-17 16:18:07,746 DEBUG [_base_client.py]: 1002 - _retry_request - 1 retry left
2024-06-17 16:18:07,746 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 0.944941 seconds
2024-06-17 16:18:08,698 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': None}], 'model': 'gpt-3.5-turbo'}}
2024-06-17 16:18:08,700 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-06-17 16:18:13,711 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-06-17 16:18:13,712 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-06-17 16:18:13,713 DEBUG [_base_client.py]: 1004 - _retry_request - 0 retries left
2024-06-17 16:18:13,713 INFO [_base_client.py]: 1007 - _retry_request - Retrying request to /chat/completions in 1.836510 seconds
2024-06-17 16:18:15,559 DEBUG [_base_client.py]: 439 - _build_request - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': None}], 'model': 'gpt-3.5-turbo'}}
2024-06-17 16:18:15,562 DEBUG [_trace.py]: 45 - trace - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-06-17 16:18:20,570 DEBUG [_trace.py]: 45 - trace - connect_tcp.failed exception=ConnectTimeout(TimeoutError('timed out'))
2024-06-17 16:18:20,570 DEBUG [_base_client.py]: 924 - _request - Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 69, in map_httpcore_exceptions
    yield
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 233, in handle_request
    resp = self._pool.handle_request(req)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 216, in handle_request
    raise exc from None
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 99, in handle_request
    raise exc
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 76, in handle_request
    stream = self._connect(request)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_sync\connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_backends\sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\test\project_init\venv\lib\site-packages\openai\_base_client.py", line 918, in _request
    response = self._client.send(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_client.py", line 1015, in _send_single_request
    response = transport.handle_request(request)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 232, in handle_request
    with map_httpcore_exceptions():
  File "D:\Python310\lib\contextlib.py", line 153, in __exit__
    self.gen.throw(typ, value, traceback)
  File "D:\test\project_init\venv\lib\site-packages\httpx\_transports\default.py", line 86, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: timed out
2024-06-17 16:18:20,572 DEBUG [_base_client.py]: 936 - _request - Raising timeout error
2024-06-17 16:18:20,573 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:18:20] "GET /user/register HTTP/1.1" 200 -
2024-06-17 16:19:53,966 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:19:53,968 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:19:53,988 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-06-17 16:19:54,632 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:19:54,634 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:19:54,651 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-06-17 16:19:54,657 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-06-17 16:19:54,711 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-06-17 16:19:56,961 ERROR [resource.py]: 15 - get - error
2024-06-17 16:19:56,962 DEBUG [resource.py]: 16 - get - debug
2024-06-17 16:19:56,962 INFO [resource.py]: 17 - get - info
2024-06-17 16:19:56,974 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:56] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-06-17 16:19:57,611 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:57] "GET /user/register?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2024-06-17 16:19:57,616 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:57] "GET /user/register?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2024-06-17 16:19:57,647 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:57] "GET /user/register?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1" 200 -
2024-06-17 16:19:57,648 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:57] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-06-17 16:19:57,769 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:19:57] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-06-17 16:20:36,739 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:20:36,741 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:20:36,761 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-06-17 16:20:37,447 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:20:37,448 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:20:37,466 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-06-17 16:20:37,469 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-06-17 16:20:37,530 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-06-17 16:20:38,281 ERROR [resource.py]: 15 - get - error
2024-06-17 16:20:38,282 DEBUG [resource.py]: 16 - get - debug
2024-06-17 16:20:38,283 INFO [resource.py]: 17 - get - info
2024-06-17 16:20:38,290 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "[35m[1mGET /user/register HTTP/1.1[0m" 500 -
2024-06-17 16:20:38,468 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "GET /user/register?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2024-06-17 16:20:38,470 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "GET /user/register?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2024-06-17 16:20:38,481 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "GET /user/register?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1" 200 -
2024-06-17 16:20:38,482 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-06-17 16:20:38,622 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:20:38] "GET /user/register?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-06-17 16:21:06,404 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:21:06,406 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:21:06,426 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-06-17 16:21:07,870 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:21:07,872 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:21:07,889 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-06-17 16:21:07,894 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-06-17 16:21:07,993 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
2024-06-17 16:21:08,955 ERROR [resource.py]: 15 - get - error
2024-06-17 16:21:08,955 DEBUG [resource.py]: 16 - get - debug
2024-06-17 16:21:08,956 INFO [resource.py]: 17 - get - info
2024-06-17 16:21:08,958 INFO [_internal.py]: 225 - _log - 127.0.0.1 - - [17/Jun/2024 16:21:08] "GET /user/register HTTP/1.1" 200 -
2024-06-17 16:21:14,055 INFO [_internal.py]: 225 - _log -  * Detected change in 'D:\\test\\project_init\\apps\\user\\resource.py', reloading
2024-06-17 16:21:14,667 INFO [_internal.py]: 225 - _log -  * Restarting with stat
2024-06-17 16:21:16,510 DEBUG [_config.py]: 80 - load_ssl_context - load_ssl_context verify=True cert=None trust_env=True http2=False
2024-06-17 16:21:16,512 DEBUG [_config.py]: 146 - load_ssl_context_verify - load_verify_locations cafile='D:\\test\\project_init\\venv\\lib\\site-packages\\certifi\\cacert.pem'
2024-06-17 16:21:16,544 WARNING [_internal.py]: 225 - _log -  * Debugger is active!
2024-06-17 16:21:16,552 INFO [_internal.py]: 225 - _log -  * Debugger PIN: 426-818-020
2024-06-17 16:21:16,651 INFO [_internal.py]: 225 - _log -  * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)
